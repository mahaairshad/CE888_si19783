{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.4"
    },
    "colab": {
      "name": "FBCSP_v6.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mahaairshad/CE888_si19783/blob/master/FBCSP/FBCSP_v6.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ImdiDRtAGyiL",
        "colab_type": "code",
        "outputId": "d36cd4fa-fc12-46ec-a823-0cbb0fe8adda",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 272
        }
      },
      "source": [
        "!pip install PyDrive"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: PyDrive in /usr/local/lib/python3.6/dist-packages (1.3.1)\n",
            "Requirement already satisfied: oauth2client>=4.0.0 in /usr/local/lib/python3.6/dist-packages (from PyDrive) (4.1.3)\n",
            "Requirement already satisfied: PyYAML>=3.0 in /usr/local/lib/python3.6/dist-packages (from PyDrive) (3.13)\n",
            "Requirement already satisfied: google-api-python-client>=1.2 in /usr/local/lib/python3.6/dist-packages (from PyDrive) (1.7.11)\n",
            "Requirement already satisfied: six>=1.6.1 in /usr/local/lib/python3.6/dist-packages (from oauth2client>=4.0.0->PyDrive) (1.12.0)\n",
            "Requirement already satisfied: rsa>=3.1.4 in /usr/local/lib/python3.6/dist-packages (from oauth2client>=4.0.0->PyDrive) (4.0)\n",
            "Requirement already satisfied: httplib2>=0.9.1 in /usr/local/lib/python3.6/dist-packages (from oauth2client>=4.0.0->PyDrive) (0.11.3)\n",
            "Requirement already satisfied: pyasn1-modules>=0.0.5 in /usr/local/lib/python3.6/dist-packages (from oauth2client>=4.0.0->PyDrive) (0.2.8)\n",
            "Requirement already satisfied: pyasn1>=0.1.7 in /usr/local/lib/python3.6/dist-packages (from oauth2client>=4.0.0->PyDrive) (0.4.8)\n",
            "Requirement already satisfied: google-auth>=1.4.1 in /usr/local/lib/python3.6/dist-packages (from google-api-python-client>=1.2->PyDrive) (1.7.2)\n",
            "Requirement already satisfied: uritemplate<4dev,>=3.0.0 in /usr/local/lib/python3.6/dist-packages (from google-api-python-client>=1.2->PyDrive) (3.0.1)\n",
            "Requirement already satisfied: google-auth-httplib2>=0.0.3 in /usr/local/lib/python3.6/dist-packages (from google-api-python-client>=1.2->PyDrive) (0.0.3)\n",
            "Requirement already satisfied: setuptools>=40.3.0 in /usr/local/lib/python3.6/dist-packages (from google-auth>=1.4.1->google-api-python-client>=1.2->PyDrive) (45.2.0)\n",
            "Requirement already satisfied: cachetools<3.2,>=2.0.0 in /usr/local/lib/python3.6/dist-packages (from google-auth>=1.4.1->google-api-python-client>=1.2->PyDrive) (3.1.1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YUE7y2aWHJk2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "from pydrive.auth import GoogleAuth\n",
        "from pydrive.drive import GoogleDrive\n",
        "from google.colab import auth\n",
        "from oauth2client.client import GoogleCredentials"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hg_x9iK8HLDI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "auth.authenticate_user()\n",
        "gauth = GoogleAuth()\n",
        "gauth.credentials = GoogleCredentials.get_application_default()\n",
        "drive = GoogleDrive(gauth)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zEQnCJCSwIn-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "fname_S1='ParsedMEGData_P5.mat'\n",
        "fname_S2='ParsedMEGData_P5_S2.mat'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0qYQwxdAHPn4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "download = drive.CreateFile({'id': '1R72DvIB6ni4pkqxxwOpSGnvF480-gFZZ'})\n",
        "download.GetContentFile(fname_S1)\n",
        "download = drive.CreateFile({'id': '1vlhrL0rUnrgutOgJeZlkfIwOcONDNf_z'})\n",
        "download.GetContentFile(fname_S2)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1KduWx_MXJvu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Import Libraries\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from scipy.io import loadmat\n",
        "from scipy.signal import butter, sosfilt, sosfreqz\n",
        "from numpy import linalg as LA\n",
        "from scipy import linalg as LAS\n",
        "from sklearn.model_selection import GridSearchCV    # Import library for grid search\n",
        "from sklearn import svm                             # Import SVM model library\n",
        "from sklearn import metrics                         # Evaluating Accuracy\n",
        "from sklearn.metrics import accuracy_score as acc\n",
        "from sklearn.metrics import cohen_kappa_score       # Evaluating Kappa score\n",
        "from sklearn.model_selection import cross_val_score # Cross Validation\n",
        "from sklearn.metrics import make_scorer"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VJHbbP45Z80o",
        "colab_type": "text"
      },
      "source": [
        "### 1. Access dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hs4tjMOYZ80u",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Loading single P's dataset\n",
        "# s : (1,1)\n",
        "# x : (3500,300,200)\n",
        "# y : (1,200)\n",
        "# c : ~(300,1)\n",
        "# ci : ~(300,1)\n",
        "# classInfo : (4,2)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2n8PyvrRZ81A",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "annotsS1 = loadmat(fname_S1)\n",
        "annotsS2 = loadmat(fname_S2)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T-7t9zNHZ81Q",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "mdata1 = annotsS1['MEGdata']\n",
        "mtype1 = mdata1.dtype\n",
        "ndata1 = {n: mdata1[n][0,0] for n in mtype1.names}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pGcXLoPfZ81e",
        "colab_type": "code",
        "outputId": "38e0c0cf-f88b-44ce-a8fb-0cbf5d841f58",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 101
        }
      },
      "source": [
        "s_sess1=ndata1['s']\n",
        "x_sess1=ndata1['x']\n",
        "y_sess1=ndata1['y']\n",
        "c_sess1=ndata1['c']\n",
        "ci_sess1=ndata1['ci']\n",
        "class_info_Sess1=ndata1['classInfo']\n",
        "#class_info_Sess1=\n",
        "print(s_sess1.shape,'\\n',x_sess1.shape,'\\n', y_sess1.shape, '\\n', c_sess1.shape, '\\n',ci_sess1.shape)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(1, 1) \n",
            " (3500, 297, 200) \n",
            " (1, 200) \n",
            " (297, 1) \n",
            " (297, 1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2sHKbEjzZ81n",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "mdata2 = annotsS2['MEGdata']\n",
        "mtype2 = mdata2.dtype\n",
        "ndata2 = {n: mdata2[n][0,0] for n in mtype2.names}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fhfn7xuYZ811",
        "colab_type": "code",
        "outputId": "771b871f-56b4-4466-92d8-13dfa14fdd5a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 101
        }
      },
      "source": [
        "s_sess2=ndata2['s']\n",
        "x_sess2=ndata2['x']\n",
        "y_sess2=ndata2['y']\n",
        "c_sess2=ndata2['c']\n",
        "ci_sess2=ndata2['ci']\n",
        "class_info_Sess2=ndata2['classInfo']\n",
        "#class_info_Sess2=\n",
        "print(s_sess2.shape,'\\n',x_sess2.shape,'\\n', y_sess2.shape, '\\n', c_sess2.shape, '\\n',ci_sess2.shape)"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(1, 1) \n",
            " (3500, 297, 200) \n",
            " (1, 200) \n",
            " (297, 1) \n",
            " (297, 1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y9_4-sM4Z82B",
        "colab_type": "text"
      },
      "source": [
        "### 2. Considering the common channels from Session1 and Session2"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m_LB1rZitUgH",
        "colab_type": "code",
        "outputId": "6b938211-4b34-407f-b971-5a553e1ab86a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "import re\n",
        "chnl_names=c_sess1.reshape(len(c_sess1),)\n",
        "chnl_names=str(chnl_names)\n",
        "chnl_names=re.findall('\\[\\'.*?\\'\\]',chnl_names)\n",
        "len(chnl_names)\n",
        "channel=[]\n",
        "for i in range (len(chnl_names)):\n",
        "    k=str(chnl_names[i])[2:-2]\n",
        "    channel.append(k)\n",
        "for i in range (len(channel)):\n",
        "    channel[i]=re.sub(r'(?<=[.G])(?=[^\\s])', r' ', channel[i])\n",
        "len(channel)"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "297"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JgL2ou7NvbuJ",
        "colab_type": "code",
        "outputId": "07117c7c-f26a-47bb-f46b-5f633c2d0515",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "exclude_chs=['MEG 1633',\n",
        " 'MEG 1632',\n",
        " 'MEG 1631',\n",
        " 'MEG 1643',\n",
        " 'MEG 1642',\n",
        " 'MEG 1641',\n",
        " 'MEG 1713',\n",
        " 'MEG 1712',\n",
        " 'MEG 1711',\n",
        " 'MEG 1723',\n",
        " 'MEG 1722',\n",
        " 'MEG 1721',\n",
        " 'MEG 1733',\n",
        " 'MEG 1732',\n",
        " 'MEG 1731',\n",
        " 'MEG 1743',\n",
        " 'MEG 1742',\n",
        " 'MEG 1741',\n",
        " 'MEG 1833',\n",
        " 'MEG 1832',\n",
        " 'MEG 1831',\n",
        " 'MEG 1843',\n",
        " 'MEG 1842',\n",
        " 'MEG 1841',\n",
        " 'MEG 1913',\n",
        " 'MEG 1912',\n",
        " 'MEG 1911',\n",
        " 'MEG 1923',\n",
        " 'MEG 1922',\n",
        " 'MEG 1921',\n",
        " 'MEG 1933',\n",
        " 'MEG 1932',\n",
        " 'MEG 1931',\n",
        " 'MEG 1943',\n",
        " 'MEG 1942',\n",
        " 'MEG 1941',\n",
        " 'MEG 2013',\n",
        " 'MEG 2012',\n",
        " 'MEG 2011',\n",
        " 'MEG 2023',\n",
        " 'MEG 2022',\n",
        " 'MEG 2021',\n",
        " 'MEG 2033',\n",
        " 'MEG 2032',\n",
        " 'MEG 2031',\n",
        " 'MEG 2043',\n",
        " 'MEG 2042',\n",
        " 'MEG 2041',\n",
        " 'MEG 2113',\n",
        " 'MEG 2112',\n",
        " 'MEG 2111',\n",
        " 'MEG 2123',\n",
        " 'MEG 2122',\n",
        " 'MEG 2121',\n",
        " 'MEG 2133',\n",
        " 'MEG 2132',\n",
        " 'MEG 2131',\n",
        " 'MEG 2143',\n",
        " 'MEG 2142',\n",
        " 'MEG 2141',\n",
        " 'MEG 2233',\n",
        " 'MEG 2232',\n",
        " 'MEG 2231',\n",
        " 'MEG 2243',\n",
        " 'MEG 2242',\n",
        " 'MEG 2241',\n",
        " 'MEG 2313',\n",
        " 'MEG 2312',\n",
        " 'MEG 2311',\n",
        " 'MEG 2323',\n",
        " 'MEG 2322',\n",
        " 'MEG 2321',\n",
        " 'MEG 2333',\n",
        " 'MEG 2332',\n",
        " 'MEG 2331',\n",
        " 'MEG 2343',\n",
        " 'MEG 2342',\n",
        " 'MEG 2341',\n",
        " 'MEG 2433',\n",
        " 'MEG 2432',\n",
        " 'MEG 2431',\n",
        " 'MEG 2443',\n",
        " 'MEG 2442',\n",
        " 'MEG 2441',\n",
        " 'MEG 2513',\n",
        " 'MEG 2512',\n",
        " 'MEG 2511',\n",
        " 'MEG 2523',\n",
        " 'MEG 2522',\n",
        " 'MEG 2521',\n",
        " 'MEG 2533',\n",
        " 'MEG 2532',\n",
        " 'MEG 2531',\n",
        " 'MEG 2543',\n",
        " 'MEG 2542',\n",
        " 'MEG 2541',\n",
        " 'MEG 2633',\n",
        " 'MEG 2632',\n",
        " 'MEG 2631',\n",
        " 'MEG 1533',\n",
        " 'MEG 1532',\n",
        " 'MEG 1531',\n",
        " ]\n",
        "exclude_chs=np.asarray(exclude_chs)\n",
        "exclude_chs.shape"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(102,)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-6GVnL0-Z82D",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "cmn_chnls=np.intersect1d(ci_sess1,ci_sess2)\n",
        "cmn_chnls=cmn_chnls.reshape(len(cmn_chnls),1) #reshaping so cmn_chnls, sess1_x and sess2_x have same shape"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gwsDFRI84J12",
        "colab_type": "code",
        "outputId": "98343170-6b4b-439f-a953-8a39a9cd88a2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "channel=np.asarray(channel)\n",
        "channel=channel.reshape(len(channel),1)\n",
        "ids_of_chs=np.concatenate((cmn_chnls,channel), axis=1)\n",
        "ids_of_chs.shape"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(297, 2)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QInt1wQRZ82K",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "valid_chnl_ind1=np.array([],dtype=int)\n",
        "valid_chnl_ind2=np.array([],dtype=int)\n",
        "\n",
        "for i in range(0,len(ci_sess1)):    #Stores the index of common channels b/w sess1_x and cmn_chnls\n",
        "    for j in range(0,len(ids_of_chs)):\n",
        "        if (ci_sess1[i,0]==int(ids_of_chs[j,0])) and (ids_of_chs[j,1] not in exclude_chs):\n",
        "            valid_chnl_ind1=np.append(valid_chnl_ind1,i)\n",
        "            \n",
        "for i in range(0,len(ci_sess2)):    #Stores the index of common channels b/w sess2_x and cmn_chnls\n",
        "    for j in range(0,len(ids_of_chs)):\n",
        "        if (ci_sess2[i,0]==int(ids_of_chs[j,0])) and (ids_of_chs[j,1] not in exclude_chs):\n",
        "            valid_chnl_ind2=np.append(valid_chnl_ind2,i)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V05u2GHhZ82a",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data1=x_sess1[:,valid_chnl_ind1,:] #(samples,channels,trials)\n",
        "data2=x_sess2[:,valid_chnl_ind2,:] #(samples,channels,trials)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v4Gm9CZTZ82r",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Comibining session1 and session2 data (along 3rd axis(trials))\n",
        "MEGdata_s= s_sess1\n",
        "MEGdata_x= np.concatenate((data1,data2), axis=2)\n",
        "MEGdata_y= np.concatenate((y_sess1,y_sess2), axis=1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NWaL1ZV1Z824",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "MEGdata_c= c_sess1[valid_chnl_ind1]\n",
        "MEGdata_ci= cmn_chnls.copy()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hpliaq6dZ83E",
        "colab_type": "code",
        "outputId": "d81efb2e-c98e-468a-de21-c549319d572d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 101
        }
      },
      "source": [
        "print(MEGdata_s.shape,'\\n',MEGdata_x.shape,'\\n', MEGdata_y.shape, '\\n', MEGdata_c.shape, '\\n',MEGdata_ci.shape)"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(1, 1) \n",
            " (3500, 199, 400) \n",
            " (1, 400) \n",
            " (199, 1) \n",
            " (297, 1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1MmX1W5qZ83L",
        "colab_type": "text"
      },
      "source": [
        "### 3. Implementation of Butterworth Filter"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VJ34GR8Puyi5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "Class_prob=np.array([[1, 2], #Hand Foot\n",
        "                  [1, 3], #Hand Word\n",
        "                  [1, 4], #Hand Sub\n",
        "                  [2, 3], #Foot Word\n",
        "                  [2, 4], #Foot Sub\n",
        "                  [3, 4] #Foot Sub\n",
        "])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oFxGg--l_shZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from zipfile import ZipFile\n",
        "# create a ZipFile object\n",
        "zipObj = ZipFile('DOWNLOAD_'+fname_S1+'.zip', 'w')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UJFekbxQZ83W",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        " for class_type in range (len(Class_prob)):\n",
        "  #Selecting Frequency band, Sampling range, Base range(noise) and Classes\n",
        "  FreqBand1=np.array([8, 12]) #Freqband\n",
        "  FreqBand2=np.array([13, 17])\n",
        "  SampRangeSec=np.array([2.5, 6.])#actTs\n",
        "  BaseRangeSec=np.array([1, 2]) #baseTs\n",
        "  Classes=Class_prob[class_type] #class1 class2\n",
        "\n",
        "  SampRange=s_sess1*SampRangeSec\n",
        "  SampRangeind=np.arange(1250,3000,1,dtype=int)#saves index for given range of time\n",
        "  BaseRange=s_sess1*BaseRangeSec\n",
        "  BaseRangeind=np.arange(500,1000,1,dtype=int)#saves index for given range of time\n",
        "\n",
        "  #Separating data in classification of interest\n",
        "  cMEGdata_y_ind=np.array([],dtype=int)\n",
        "\n",
        "  for i in range(0,MEGdata_y.size): \n",
        "      if (MEGdata_y[0,i]==Classes[0])or(MEGdata_y[0,i]==Classes[1]):\n",
        "          cMEGdata_y_ind=np.append(cMEGdata_y_ind,i)\n",
        "\n",
        "  cMEGdata_x=MEGdata_x[:,:,cMEGdata_y_ind] #(samples,channels,trials)\n",
        "  cMEGdata_y=MEGdata_y[0,cMEGdata_y_ind]\n",
        "\n",
        "  def butter_bandpass(lowcut, highcut, fs, order):\n",
        "          nyq = 0.5 * fs\n",
        "          low = lowcut / nyq\n",
        "          high = highcut / nyq\n",
        "          sos = butter(order, [low, high], analog=True, btype='bandpass', output='sos')\n",
        "          return sos\n",
        "\n",
        "  def butter_bandpass_filter(data, lowcut, highcut, fs, order):\n",
        "          sos = butter_bandpass(lowcut, highcut, fs, order=order)\n",
        "          y = sosfilt(sos, data)\n",
        "          return y\n",
        "\n",
        "  #(samples,channels,trials)--> (channels,trials,samples)\n",
        "  bMEGdata_x_1=np.zeros((cMEGdata_x[0,:,0].size,cMEGdata_x[0,0,:].size,SampRangeind.size))\n",
        "  bMEGdata_x_2=np.zeros((cMEGdata_x[0,:,0].size,cMEGdata_x[0,0,:].size,SampRangeind.size))\n",
        "\n",
        "  for trial in range(0,bMEGdata_x_1[0,:,0].size): #(channels,trials,samples) size of trial\n",
        "      for channel in range(0,bMEGdata_x_1[:,0,0].size): #(channels,trials,samples) size of channel\n",
        "          temp=cMEGdata_x[:,channel,trial] #(samples,channels,trials)\n",
        "          temp=temp-np.mean(temp[BaseRangeind])\n",
        "          f_temp1=butter_bandpass_filter(temp,FreqBand1[0],FreqBand1[1],MEGdata_s[0],4)\n",
        "          f_temp1=f_temp1[SampRangeind]\n",
        "          f_temp2=butter_bandpass_filter(temp,FreqBand2[0],FreqBand2[1],MEGdata_s[0],4)\n",
        "          f_temp2=f_temp2[SampRangeind]\n",
        "          bMEGdata_x_1[channel,trial,:]=f_temp1 #(channels,trials,samples)\n",
        "          bMEGdata_x_2[channel,trial,:]=f_temp2\n",
        "\n",
        "  ### 4.Separating train and validation data\n",
        "\n",
        "  # Splitting train/test data in 50:50\n",
        "  size_Train_Test=int(bMEGdata_x_1[0,:,0].size/2)\n",
        "  bMEGdata_x_Train_1=bMEGdata_x_1[:,0:size_Train_Test,:]\n",
        "  bMEGdata_y_Train=cMEGdata_y[0:size_Train_Test]\n",
        "  bMEGdata_x_Test_1=bMEGdata_x_1[:,size_Train_Test:(size_Train_Test*2),:]\n",
        "  bMEGdata_y_Test=cMEGdata_y[size_Train_Test:(size_Train_Test*2)]\n",
        "\n",
        "  c1_bMEGdata_y_Train_ind=np.array([],dtype=int) #Getting index for class1 and class2 data\n",
        "  c2_bMEGdata_y_Train_ind=np.array([],dtype=int)\n",
        "\n",
        "  for i in range(0,bMEGdata_y_Train.size): \n",
        "      if (bMEGdata_y_Train[i]==Classes[0]):\n",
        "          c1_bMEGdata_y_Train_ind=np.append(c1_bMEGdata_y_Train_ind,i)\n",
        "      else:\n",
        "          c2_bMEGdata_y_Train_ind=np.append(c2_bMEGdata_y_Train_ind,i)\n",
        "\n",
        "  # x and y values separated for class and 2\n",
        "  c1_bMEGdata_x_Train_1=bMEGdata_x_Train_1[:,c1_bMEGdata_y_Train_ind,:]\n",
        "  c1_bMEGdata_y_Train=bMEGdata_y_Train[c1_bMEGdata_y_Train_ind]\n",
        "  c2_bMEGdata_x_Train_1=bMEGdata_x_Train_1[:,c2_bMEGdata_y_Train_ind,:]\n",
        "  c2_bMEGdata_y_Train=bMEGdata_y_Train[c2_bMEGdata_y_Train_ind]\n",
        "\n",
        "  # Merging trial and sample dimensions into one: (channels,trials,samples)-->(channels,trials*samples)\n",
        "  c1_feat_Train_1=c1_bMEGdata_x_Train_1.reshape((c1_bMEGdata_x_Train_1[:,0,0].size,(c1_bMEGdata_x_Train_1[0,:,0].size*c1_bMEGdata_x_Train_1[0,0,:].size)))\n",
        "  c2_feat_Train_1=c2_bMEGdata_x_Train_1.reshape((c2_bMEGdata_x_Train_1[:,0,0].size,(c2_bMEGdata_x_Train_1[0,:,0].size*c2_bMEGdata_x_Train_1[0,0,:].size)))\n",
        "\n",
        "\n",
        "  # Splitting train/test data in 50:50\n",
        "  size_Train_Test=int(bMEGdata_x_2[0,:,0].size/2)\n",
        "  bMEGdata_x_Train_2=bMEGdata_x_2[:,0:size_Train_Test,:]\n",
        "  bMEGdata_y_Train=cMEGdata_y[0:size_Train_Test]\n",
        "  bMEGdata_x_Test_2=bMEGdata_x_2[:,size_Train_Test:(size_Train_Test*2),:]\n",
        "  bMEGdata_y_Test=cMEGdata_y[size_Train_Test:(size_Train_Test*2)]\n",
        "\n",
        "  c1_bMEGdata_y_Train_ind=np.array([],dtype=int) #Getting index for class1 and class2 data\n",
        "  c2_bMEGdata_y_Train_ind=np.array([],dtype=int)\n",
        "\n",
        "  for i in range(0,bMEGdata_y_Train.size): \n",
        "      if (bMEGdata_y_Train[i]==Classes[0]):\n",
        "          c1_bMEGdata_y_Train_ind=np.append(c1_bMEGdata_y_Train_ind,i)\n",
        "      else:\n",
        "          c2_bMEGdata_y_Train_ind=np.append(c2_bMEGdata_y_Train_ind,i)\n",
        "\n",
        "  # x and y values separated for class and 2\n",
        "  c1_bMEGdata_x_Train_2=bMEGdata_x_Train_2[:,c1_bMEGdata_y_Train_ind,:]\n",
        "  c1_bMEGdata_y_Train=bMEGdata_y_Train[c1_bMEGdata_y_Train_ind]\n",
        "  c2_bMEGdata_x_Train_2=bMEGdata_x_Train_2[:,c2_bMEGdata_y_Train_ind,:]\n",
        "  c2_bMEGdata_y_Train=bMEGdata_y_Train[c2_bMEGdata_y_Train_ind]\n",
        "\n",
        "  # Merging trial and sample dimensions into one: (channels,trials,samples)-->(channels,trials*samples)\n",
        "  c1_feat_Train_2=c1_bMEGdata_x_Train_2.reshape((c1_bMEGdata_x_Train_2[:,0,0].size,(c1_bMEGdata_x_Train_2[0,:,0].size*c1_bMEGdata_x_Train_2[0,0,:].size)))\n",
        "  c2_feat_Train_2=c2_bMEGdata_x_Train_2.reshape((c2_bMEGdata_x_Train_2[:,0,0].size,(c2_bMEGdata_x_Train_2[0,:,0].size*c2_bMEGdata_x_Train_2[0,0,:].size)))\n",
        "\n",
        "  ### 5. Implementation of CSP\n",
        "\n",
        "  def CSP_projectionMat(class1, class2):\n",
        "          #1 Find spatial covariance for both classes of data\n",
        "          C1= np.matmul(class1,np.transpose(class1))/np.trace(np.matmul(class1,np.transpose(class1)))\n",
        "          C2= np.matmul(class2,np.transpose(class2))/np.trace(np.matmul(class2,np.transpose(class2)))\n",
        "          #2 Find composite spatial covariance\n",
        "          Cc=C1+C2\n",
        "          #3 Find eigen vectors and eigen values for Cc\n",
        "          eigvalCc, eigvecCc= LA.eig(Cc)\n",
        "          ## form eigval & eigvec in descending order and form diagonal matrix for eigval\n",
        "          temp=np.sort(eigvalCc)  #sorts in ascending\n",
        "          eigvalCc=temp[::-1]     #sorts in descending\n",
        "          Cc_ind=np.argsort(temp) #finds arg for asc\n",
        "          Cc_ind=Cc_ind[::-1]     #finds arg for des\n",
        "          eigvalCc=np.diag(eigvalCc) #form diagonal matrix\n",
        "          eigvecCc=eigvecCc[:,Cc_ind] #finds respective eigen vectors for the eig values\n",
        "          #4 Find whitening transform\n",
        "          P=np.matmul(LA.inv(eigvalCc),np.transpose(eigvecCc))\n",
        "          P=np.sqrt(np.square(P)) #getting rid of the -ve values for simplicity here(MUST BE REMOVED)\n",
        "          P=np.sqrt(P)\n",
        "          #5 Find S1 and S2 for C1 and C2\n",
        "          S1=np.matmul(P,C1) #S1=PC1P'\n",
        "          S1=np.matmul(S1,np.transpose(P))\n",
        "          S2=np.matmul(P,C2) #S2=PC2P'\n",
        "          S2=np.matmul(S2,np.transpose(P))\n",
        "          #6 Find generalized eigenvector and eigenvalues for S1 and S2\n",
        "          eigvalB,B=LAS.eig(S1,S2, left=False, right=True)\n",
        "          #7 Find W\n",
        "          eigvalB=np.sort(eigvalB) #arranging in ascending to have the lowest eigenvalue on top and highest on bottom\n",
        "          B_ind=np.argsort(eigvalB)\n",
        "          B=B[:,B_ind]\n",
        "          W=np.matmul(np.transpose(B),P)\n",
        "          return W\n",
        "\n",
        "  W1=CSP_projectionMat(c1_feat_Train_1,c2_feat_Train_1)\n",
        "  W2=CSP_projectionMat(c1_feat_Train_2,c2_feat_Train_2)\n",
        "\n",
        "  # TRAIN DATA\n",
        "  #Finding 2 best features for each trial\n",
        "  Train_x_1=np.zeros((bMEGdata_x_Train_1[0,:,0].size,2)) #bMEGdata_x_Train=(channels,trials,samples)\n",
        "  Train_x_2=np.zeros((bMEGdata_x_Train_1[0,:,0].size,2))\n",
        "\n",
        "  for trial in range(0,bMEGdata_x_Train_1[0,:,0].size): #(channels,trials,samples) size of trial\n",
        "      temp=bMEGdata_x_Train_1[:,trial,:] #(channels,trials,samples)-->(channels,samples)\n",
        "      Z=np.matmul(np.transpose(W1),temp) #Z: CSP Features\n",
        "      Feat=np.log(np.var(Z, axis=1)/np.sum(np.var(Z, axis=1))) #log of variance across each channel\n",
        "      Train_x_1[trial,:]=[Feat[0], Feat[len(Feat)-1]] #2 best features representing each trial extracted\n",
        "\n",
        "  for trial in range(0,bMEGdata_x_Train_1[0,:,0].size): #(channels,trials,samples) size of trial\n",
        "      temp=bMEGdata_x_Train_2[:,trial,:] #(channels,trials,samples)-->(channels,samples)\n",
        "      Z=np.matmul(np.transpose(W2),temp) #Z: CSP Features\n",
        "      Feat=np.log(np.var(Z, axis=1)/np.sum(np.var(Z, axis=1))) #log of variance across each channel\n",
        "      Train_x_2[trial,:]=[Feat[0], Feat[len(Feat)-1]] #2 best features representing each trial extracted\n",
        "\n",
        "\n",
        "  # TEST DATA\n",
        "  #Finding 2 best features for each trial\n",
        "\n",
        "  Test_x_1=np.zeros((bMEGdata_x_Test_1[0,:,0].size,2)) #bMEGdata_x_Test=(channels,trials,samples)\n",
        "  Test_x_2=np.zeros((bMEGdata_x_Test_1[0,:,0].size,2))\n",
        "\n",
        "  for trial in range(0,bMEGdata_x_Test_1[0,:,0].size): #(channels,trials,samples) size of trial\n",
        "      temp=bMEGdata_x_Test_1[:,trial,:] #(channels,trials,samples)-->(channels,samples)\n",
        "      Z=np.matmul(np.transpose(W1),temp) #Z: CSP Features\n",
        "      Feat=np.log(np.var(Z, axis=1)/np.sum(np.var(Z, axis=1))) #log of variance across each channel\n",
        "      Test_x_1[trial,:]=[Feat[0], Feat[len(Feat)-1]] #2 best features representing each trial extracted\n",
        "\n",
        "  for trial in range(0,bMEGdata_x_Test_1[0,:,0].size): #(channels,trials,samples) size of trial\n",
        "      temp=bMEGdata_x_Test_2[:,trial,:] #(channels,trials,samples)-->(channels,samples)\n",
        "      Z=np.matmul(np.transpose(W2),temp) #Z: CSP Features\n",
        "      Feat=np.log(np.var(Z, axis=1)/np.sum(np.var(Z, axis=1))) #log of variance across each channel\n",
        "      Test_x_2[trial,:]=[Feat[0], Feat[len(Feat)-1]] #2 best features representing each trial extracted\n",
        "\n",
        "  Train_x=np.hstack([Train_x_1,Train_x_2])#,Train_x_3,Train_x_4\n",
        "  Test_x=np.hstack([Test_x_1,Test_x_2])#,Test_x_3,Test_x_4\n",
        "  Train_y=bMEGdata_y_Train #Y_train\n",
        "  Test_y=bMEGdata_y_Test\n",
        "\n",
        "  np.save(fname_S1+'_'+str(Classes)+'_Train_x', Train_x)\n",
        "  np.save(fname_S1+'_'+str(Classes)+'_Test_x', Test_x)\n",
        "  np.save(fname_S1+'_'+str(Classes)+'_Train_y', Train_y)\n",
        "  np.save(fname_S1+'_'+str(Classes)+'_Test_y', Test_y)\n",
        "  \n",
        "  zipObj.write(fname_S1+'_'+str(Classes)+'_Train_x'+'.npy')\n",
        "  zipObj.write(fname_S1+'_'+str(Classes)+'_Test_x'+'.npy')\n",
        "  zipObj.write(fname_S1+'_'+str(Classes)+'_Train_y'+'.npy')\n",
        "  zipObj.write(fname_S1+'_'+str(Classes)+'_Test_y'+'.npy')\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Iw9ETV6P-KiC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# close the Zip File\n",
        "zipObj.close()"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}