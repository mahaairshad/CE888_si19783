# -*- coding: utf-8 -*-
"""DSDM_Ass2_2of3

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1w-NgOpk1pWaOybjilPyoTECWFmHruBf_
"""

# ********************************** Assignment 2 ************************************
# ----------------------------------- Part (2/3) -------------------------------------
#
# This code generates the a dataset using Monte Carlo Tree Search (MCTS) algorithm 
# and Decision Tree (DT) Python 3.0.
# 
# This code is run 19 times to perform iterative learning on DT-based agents.
# The DT-based agent learns from the previous version of itself provided as a dataset.
# A 2-player tic-tac-toe game is played using UCTPlayGame() function.
# A total of 10000 games are played and the states and actions of the winner or drawer is
# is stored in a .csv file.
# 
# Written by Shahzadi Mahaa Irshad 
# Reg ID: 1901079
# CSEE, University of Essex
# Submiteed as part of the requirements for CE888- Data Science and Decision Making
# Date: 19-4-2020
# 
# For more information about the program please read the report available in the repository.

from math import *
import numpy as np
import pandas as pd
from sklearn import tree
import random

def DecisionTreePred(clf, x):
  """ Make a prediction for x using clf provided.
  """
  y=clf.predict(x)
  if x[0,y[0]]!=0: #if the move predicted is not empty
    emp_ind=np.array(np.where(x[0,:]==0)) #find all the empty boxes
    y[0]=np.random.choice(emp_ind[0,:]) #select any random index from the available empty options
  return y[0]


def ChangePlyrRep(s):
  """ Change the notation for players. Replace '1' by '2', and '2' by '1'.
      This is done to save the representation of player 2 to 1 as 
      the dataset produced contains best moves for the player with 
      notation '1', representing the current player. 
      The opponent is always '2' in the dataset.
  """
  s1 = np.array(s,dtype='int32')
  p2_ind=np.where(s1==2)
  p1_ind=np.where(s1==1)
  s1[p2_ind]=1
  s1[p1_ind]=2
  return s1

class GameState:
    """ A state of the game, i.e. the game board. These are the only functions which are
        absolutely necessary to implement UCT in any 2-player complete information deterministic 
        zero-sum game, although they can be enhanced and made quicker, for example by using a 
        GetRandomMove() function to generate a random move during rollout.
        By convention the players are numbered 1 and 2.
    """
    def __init__(self):
            self.playerJustMoved = 2 # At the root pretend the player just moved is player 2 - player 1 
                                     # has the first move
        
    def Clone(self):
        """ Create a deep clone of this game state.
        """
        st = GameState()
        st.playerJustMoved = self.playerJustMoved
        return st

    def DoMove(self, move):
        """ Update a state by carrying out the given move.
            Must update playerJustMoved.
        """
        self.playerJustMoved = 3 - self.playerJustMoved
        
    def GetMoves(self):
        """ Get all possible moves from this state.
        """
    
    def GetResult(self, playerjm):
        """ Get the game result from the viewpoint of playerjm. 
        """

    def __repr__(self):
        """ Don't need this - but good style.
        """
        pass


class OXOState:
    """ A state of the game, i.e. the game board.
        Squares in the board are in this arrangement
        012
        345
        678
        where 0 = empty, 1 = player 1 (X), 2 = player 2 (O)
    """
    def __init__(self):
        self.playerJustMoved = 2 # At the root pretend the player just moved is p2 - p1 has the first move
        self.board = [0,0,0,0,0,0,0,0,0] # 0 = empty, 1 = player 1, 2 = player 2
        
    def Clone(self):
        """ Create a deep clone of this game state.
        """
        st = OXOState()
        st.playerJustMoved = self.playerJustMoved
        st.board = self.board[:]
        return st

    def DoMove(self, move):
        """ Update a state by carrying out the given move.
            Must update playerToMove.
        """
        assert move >= 0 and move <= 8 and move == int(move) and self.board[move] == 0
        self.playerJustMoved = 3 - self.playerJustMoved
        self.board[move] = self.playerJustMoved
        
    def GetMoves(self):
        """ Get all possible moves from this state.
        """
        return [i for i in range(9) if self.board[i] == 0]
    
    def GetResult(self, playerjm):
        """ Get the game result from the viewpoint of playerjm. 
        """
        for (x,y,z) in [(0,1,2),(3,4,5),(6,7,8),(0,3,6),(1,4,7),(2,5,8),(0,4,8),(2,4,6)]:
            if self.board[x] == self.board[y] == self.board[z]:
                if self.board[x] == playerjm:
                    return 1.0
                else:
                    return 0.0
        if self.GetMoves() == []: return 0.5 # draw
        return False # Should not be possible to get here

    def __repr__(self):
        s= ""
        for i in range(9): 
            s += ".XO"[self.board[i]]
            if i % 3 == 2: s += "\n"
        return s


class Node:
    """ A node in the game tree. Note wins is always from the viewpoint of playerJustMoved.
        Crashes if state not specified.
    """
    def __init__(self, move = None, parent = None, state = None):
        self.move = move # the move that got us to this node - "None" for the root node
        self.parentNode = parent # "None" for the root node
        self.childNodes = []
        self.wins = 0
        self.visits = 0
        self.untriedMoves = state.GetMoves() # future child nodes
        self.playerJustMoved = state.playerJustMoved # the only part of the state that the Node needs later
        
    def UCTSelectChild(self):
        """ Use the UCB1 formula to select a child node. Often a constant UCTK is applied so we have
            lambda c: c.wins/c.visits + UCTK * sqrt(2*log(self.visits)/c.visits to vary the amount of
            exploration versus exploitation.
        """
        s = sorted(self.childNodes, key = lambda c: c.wins/c.visits + sqrt(2*log(self.visits)/c.visits))[-1]
        return s
    
    def AddChild(self, m, s):
        """ Remove m from untriedMoves and add a new child node for this move.
            Return the added child node
        """
        n = Node(move = m, parent = self, state = s)
        self.untriedMoves.remove(m)
        self.childNodes.append(n)
        return n
    
    def Update(self, result):
        """ Update this node - one additional visit and result additional wins. result must be from the viewpoint of playerJustmoved.
        """
        self.visits += 1
        self.wins += result

    def __repr__(self):
        return "[M:" + str(self.move) + " W/V:" + str(self.wins) + "/" + str(self.visits) + " U:" + str(self.untriedMoves) + "]"

    def TreeToString(self, indent):
        s = self.IndentString(indent) + str(self)
        for c in self.childNodes:
             s += c.TreeToString(indent+1)
        return s

    def IndentString(self,indent):
        s = "\n"
        for i in range (1,indent+1):
            s += "| "
        return s

    def ChildrenToString(self):
        s = ""
        for c in self.childNodes:
             s += str(c) + "\n"
        return s


def UCT(rootstate, itermax, verbose = False):
    """ Conduct a UCT search for itermax iterations starting from rootstate.
        Return the best move from the rootstate.
        Assumes 2 alternating players (player 1 starts), with game results in the range [0.0, 1.0]."""

    # The best move will be taken 90% of the time.
    best=int(0.9*itermax)

    rootnode = Node(state = rootstate)

    for i in range(itermax):
        node = rootnode
        state = rootstate.Clone()

        # Select
        while node.untriedMoves == [] and node.childNodes != []: # node is fully expanded and non-terminal
            node = node.UCTSelectChild()
            state.DoMove(node.move)

        # Expand
        if node.untriedMoves != []:  # if we can expand (i.e. state/node is non-terminal)
            m = random.choice(node.untriedMoves) 
            state.DoMove(m)
            node = node.AddChild(m, state)  # add child and descend tree

        # Rollout 
        
        if i<best: # Does the best move
          while state.GetMoves() != []: # while state is non-terminal
            # Change the notation if its player 2's turn
            if state.playerJustMoved==1:
              s1=ChangePlyrRep(state.board)
            else:
              s1=np.array(state.board,dtype='int32')
            s1=s1.reshape(1,9)
            m=DecisionTreePred(clf, s1)
            state.DoMove(m)
        else: # Does a random move
          while state.GetMoves() != []: # while state is non-terminal
            state.DoMove(random.choice(state.GetMoves()))


        # Backpropagate
        while node != None: # backpropagate from the expanded node and work back to the root node
            node.Update(state.GetResult(node.playerJustMoved)) # state is terminal. Update node with result from POV of node.playerJustMoved
            node = node.parentNode

    # Output some information about the tree
    if verbose: print(rootnode.TreeToString(0))
    else: print(rootnode.ChildrenToString())

    return sorted(rootnode.childNodes, key = lambda c: c.visits)[-1].move # return the move that was most visited
                
def UCTPlayGame():
    """ Play a sample game between two UCT players where each player gets a different number 
        of UCT iterations (= simulations = tree nodes).
    """
    global draws
    global wins
    global wins2
    global clf
    state_n_moveP1=np.array([],dtype=int)
    state_n_moveP2=np.array([],dtype=int)
    num_of_movesP1=0
    num_of_movesP2=0
    
    state = OXOState()
    while state.GetMoves() != []:
        print(str(state))
        if state.playerJustMoved == 1:
            m = UCT(rootstate=state, itermax=1000, verbose=False)
        else:
            m = UCT(rootstate=state, itermax=100, verbose=False)
        print("Best Move: " + str(m) + "\n")

        # The state and action done by each player is saved in a temporary array.
        temp=np.hstack((state.board,m))
        if state.playerJustMoved == 1:
            state_n_moveP2=np.append(state_n_moveP2, temp, axis=0)
            num_of_movesP2+=1
        else:
            state_n_moveP1=np.append(state_n_moveP1, temp, axis=0)
            num_of_movesP1+=1
        
        state.DoMove(m)
        if state.GetResult(state.playerJustMoved) != False:
            print(str(state))
            break
    
    state_n_moveP1=state_n_moveP1.reshape((num_of_movesP1,10))
    state_n_moveP2=state_n_moveP2.reshape((num_of_movesP2,10))
    print("P1 all states: \n",state_n_moveP1,"\n")
    print("P2 all states: \n",state_n_moveP2,"\n")
    
    # Finding the player that won.
    if state.GetResult(state.playerJustMoved) == 1.0:
        Winner= int(state.playerJustMoved) #Player x/1 wins
        print("Player " + str(state.playerJustMoved) + " wins!")
        wins=wins+1
    elif state.GetResult(state.playerJustMoved) == 0.0:
        Winner= int(state.playerJustMoved) #Player o/2 wins
        print("Player " + str(state.playerJustMoved) + " wins!")
        wins=wins+1
    else:
        Winner=0 #Match draw
        print("Nobody wins!")
        draws=draws+1
    
    # Replacing the number 1 with number 2 for data generated,
    # so that the winner/drawer is always represented as 1.
    p2_ind=np.where(state_n_moveP2[:,0:9]==2)
    p1_ind=np.where(state_n_moveP2[:,0:9]==1)
    state_n_moveP2[p2_ind]=1
    state_n_moveP2[p1_ind]=2

    # Returning the data for either of the player that won or both players if the match is a tie.
    if Winner==1:
        best_moves=state_n_moveP1
    elif Winner==2:
        best_moves=state_n_moveP2
        wins2=wins2+1
    else:
        best_moves=np.append(state_n_moveP1,state_n_moveP2, axis=0)
    return best_moves


if __name__ == "__main__":
    """ Plays 2000 games to the end using DT agents and random moves for both players. 
    """
    df= pd.read_csv('/content/Dataset_for_clf19.csv') # Get data from previous agent.
    Y=df['Move']
    Y=Y.astype(dtype='int32')
    X=df.drop(columns='Move')
    X=X.astype(dtype='int32')
    clf = tree.DecisionTreeClassifier() 
    clf = clf.fit(X, Y) # Train DT-based classifier.
    
    draws=0
    wins=0
    wins2=0
    Best_moves=np.zeros((1,10),dtype=object)

    Indexes=['s[0]','s[1]','s[2]','s[3]','s[4]','s[5]','s[6]','s[7]','s[8]','Move']

    Best_moves[0:]=Indexes
    for i in range (0,2000):#2000
        best_moves=UCTPlayGame()
        Best_moves=np.append(Best_moves, best_moves, axis=0)
        print('Game= ',i)
    
    print('Total wins = ', wins)
    print('Wins of player 2 = ', wins2)
    print('Total draws = ', draws)

    df = pd.DataFrame(Best_moves)
    df = df[1:]
    df.columns = Indexes
    df.to_csv('Dataset_for_clf20.csv', sep=',',index=False) # Export .csv new dataset file.